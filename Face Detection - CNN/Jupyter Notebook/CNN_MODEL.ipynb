{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import HeUniform, GlorotUniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import losses\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Reshape, Dense, Multiply, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "base_dir = r\"\"\n",
    "\n",
    "train_dir = r\"\"\n",
    "val_dir = r\"\"\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "channel_shift_range=50.0,\n",
    "brightness_range=[0.6, 1.4],\n",
    "horizontal_flip=True,\n",
    "zoom_range=[0.8, 1.2],\n",
    "rotation_range=25,\n",
    "shear_range=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,              \n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,               \n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# MODEL \n",
    "\n",
    "## SE ATTENTION\n",
    "\n",
    "def se_block(input_tensor , reduction =16):\n",
    "    filters = int( input_tensor.shape[-1])\n",
    "\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "\n",
    "    se = Reshape((-1, 1, filters))(se)\n",
    "\n",
    "    se = Dense(filters // reduction , activation=\"relu\")(se)\n",
    "    se = Dense(filters , activation =\"sigmoid\")(se)\n",
    "    x = Multiply()([input_tensor,se])\n",
    "\n",
    "    return x \n",
    "\n",
    "\n",
    "## RESIDUAL\n",
    "def residual_attention_block(x, filters, kernel_size=(3,3), pool_size=(2,2)):\n",
    "    shortcut = x\n",
    "\n",
    "    # SHAPE UYUMSUZLUĞU İÇİN (04.07.2025  -- 14.25)\n",
    "    \n",
    "    if x.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=(1,1), padding='same')(shortcut)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer=HeUniform())(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = se_block(x)\n",
    "\n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "## MODEL\n",
    "def model_build_with_residual_attention(img_height, img_width,num_classes):\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    x = residual_attention_block(inputs, 32)\n",
    "    x = residual_attention_block(x, 64)\n",
    "    x = residual_attention_block(x, 128)\n",
    "    x = residual_attention_block(x, 128)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = Dense(32, activation=\"relu\", kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=\"relu\", kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, activation=\"relu\", kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(128, activation=\"relu\", kernel_initializer=HeUniform())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "\n",
    "    outputs = Dense(num_classes  , activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-5),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "model = model_build_with_residual_attention(img_height, img_width, num_classes=2)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "\n",
    "class_names = [\"Brad Pitt\", \"Vijay Deverakonda\"]\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "y_train_labels = train_generator.classes  \n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train_labels),\n",
    "    y=y_train_labels\n",
    ")\n",
    "\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(weights)}\n",
    "\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "print(\"Sınıf dağılımı (train):\", np.bincount(train_generator.classes))\n",
    "print(\"Sınıf dağılımı (val):\", np.bincount(val_generator.classes))\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    callbacks = [reduce_lr,early_stop,checkpoint],\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "\n",
    "# PRED FIGURE \n",
    "\n",
    "y_pred_probs = model.predict(val_generator)\n",
    "\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "y_true = val_generator.classes\n",
    "\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
